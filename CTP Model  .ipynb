{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be5be70-c3dd-4a4a-a5c4-c4373126065c",
   "metadata": {},
   "source": [
    "#                                     CUSTOMER TRANSACTION PREDICTION \n",
    "\n",
    "\n",
    "The objective of this project is to build a machine learning system that predicts whether a customer will make a transaction in the future. The dataset consists of anonymized features, so detailed Exploratory Data Analysis (EDA) is skipped as feature names are not interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc8e187-95fa-4428-ad90-9c1d3d03da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 1: IMPORT LIBRARIES\n",
    "# ============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ceb4225-7531-45e1-ade2-acc3c3f625f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2: DATA COLLECTION\n",
    "# ============================================\n",
    "# Change the path below according to where the file is on your system\n",
    "data_path = \"train(1).csv\"   # e.g. \"train.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"‚úÖ Data loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9e06a4-b023-447d-a394-93d18e0bd99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Dataset Shape (rows, columns):\n",
      "(200000, 202)\n",
      "\n",
      "2. First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Data types:\n",
      "ID_code     object\n",
      "target       int64\n",
      "var_0      float64\n",
      "var_1      float64\n",
      "var_2      float64\n",
      "var_3      float64\n",
      "var_4      float64\n",
      "var_5      float64\n",
      "var_6      float64\n",
      "var_7      float64\n",
      "dtype: object\n",
      "\n",
      "4. Statistical summary of numeric features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>0.100490</td>\n",
       "      <td>0.300653</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_0</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>0.4084</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>10.52475</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>20.3150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_1</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>-15.0434</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>-1.60805</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>10.3768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_2</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.1171</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>10.58000</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>19.3530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_3</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>-0.0402</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>6.82500</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>13.1883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_4</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>5.0748</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>11.10825</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>16.6714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_5</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>-32.5626</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>-4.83315</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>17.2516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_6</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>2.3473</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>5.38510</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>8.4477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_7</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>5.3497</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>16.45680</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>27.6918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_8</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>-10.5055</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>0.39370</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>10.1513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count       mean       std      min        25%       50%  \\\n",
       "target  200000.0   0.100490  0.300653   0.0000   0.000000   0.00000   \n",
       "var_0   200000.0  10.679914  3.040051   0.4084   8.453850  10.52475   \n",
       "var_1   200000.0  -1.627622  4.050044 -15.0434  -4.740025  -1.60805   \n",
       "var_2   200000.0  10.715192  2.640894   2.1171   8.722475  10.58000   \n",
       "var_3   200000.0   6.796529  2.043319  -0.0402   5.254075   6.82500   \n",
       "var_4   200000.0  11.078333  1.623150   5.0748   9.883175  11.10825   \n",
       "var_5   200000.0  -5.065317  7.863267 -32.5626 -11.200350  -4.83315   \n",
       "var_6   200000.0   5.408949  0.866607   2.3473   4.767700   5.38510   \n",
       "var_7   200000.0  16.545850  3.418076   5.3497  13.943800  16.45680   \n",
       "var_8   200000.0   0.284162  3.332634 -10.5055  -2.317800   0.39370   \n",
       "\n",
       "              75%      max  \n",
       "target   0.000000   1.0000  \n",
       "var_0   12.758200  20.3150  \n",
       "var_1    1.358625  10.3768  \n",
       "var_2   12.516700  19.3530  \n",
       "var_3    8.324100  13.1883  \n",
       "var_4   12.261125  16.6714  \n",
       "var_5    0.924800  17.2516  \n",
       "var_6    6.003000   8.4477  \n",
       "var_7   19.102900  27.6918  \n",
       "var_8    2.937900  10.1513  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Missing values in each column (first 20 columns):\n",
      "ID_code    0\n",
      "target     0\n",
      "var_0      0\n",
      "var_1      0\n",
      "var_2      0\n",
      "var_3      0\n",
      "var_4      0\n",
      "var_5      0\n",
      "var_6      0\n",
      "var_7      0\n",
      "var_8      0\n",
      "var_9      0\n",
      "var_10     0\n",
      "var_11     0\n",
      "var_12     0\n",
      "var_13     0\n",
      "var_14     0\n",
      "var_15     0\n",
      "var_16     0\n",
      "var_17     0\n",
      "dtype: int64\n",
      "\n",
      "6. Number of duplicate rows:\n",
      "0\n",
      "\n",
      "7. Target variable distribution (count):\n",
      "target\n",
      "0    179902\n",
      "1     20098\n",
      "Name: count, dtype: int64\n",
      "\n",
      "8. Target variable distribution (percentage):\n",
      "target\n",
      "0    89.951\n",
      "1    10.049\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 3: BASIC CHECKS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n1. Dataset Shape (rows, columns):\")\n",
    "print(df.shape)\n",
    "\n",
    "print(\"\\n2. First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n3. Data types:\")\n",
    "print(df.dtypes.head(10))  # show first 10 types\n",
    "\n",
    "print(\"\\n4. Statistical summary of numeric features:\")\n",
    "display(df.describe().T.head(10))  # show first 10 rows for readability\n",
    "\n",
    "print(\"\\n5. Missing values in each column (first 20 columns):\")\n",
    "print(df.isnull().sum().head(20))\n",
    "\n",
    "print(\"\\n6. Number of duplicate rows:\")\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "print(\"\\n7. Target variable distribution (count):\")\n",
    "print(df[\"target\"].value_counts())\n",
    "\n",
    "print(\"\\n8. Target variable distribution (percentage):\")\n",
    "print(df[\"target\"].value_counts(normalize=True) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ec7ff8-51f6-46df-bd21-30224e3f66f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Business Problem:\n",
      "-----------------\n",
      "A bank wants to identify which customers are likely to make a specific \n",
      "transaction in the future. \n",
      "\n",
      "Data:\n",
      "-----\n",
      "- ID_code: unique identifier for each customer\n",
      "- target: 0 (no transaction), 1 (will make transaction)\n",
      "- 200 anonymized numerical features (e.g., var_0, var_1, ..., var_199)\n",
      "\n",
      "Goal:\n",
      "-----\n",
      "1. Build a classification model to predict target (0/1).\n",
      "2. Compare multiple models and choose the best one for production.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 4: DOMAIN ANALYSIS & PROBLEM DEFINITION (TEXT ONLY)\n",
    "# ============================================\n",
    "\n",
    "problem_description = \"\"\"\n",
    "Business Problem:\n",
    "-----------------\n",
    "A bank wants to identify which customers are likely to make a specific \n",
    "transaction in the future. \n",
    "\n",
    "Data:\n",
    "-----\n",
    "- ID_code: unique identifier for each customer\n",
    "- target: 0 (no transaction), 1 (will make transaction)\n",
    "- 200 anonymized numerical features (e.g., var_0, var_1, ..., var_199)\n",
    "\n",
    "Goal:\n",
    "-----\n",
    "1. Build a classification model to predict target (0/1).\n",
    "2. Compare multiple models and choose the best one for production.\n",
    "\"\"\"\n",
    "\n",
    "print(problem_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f84163f-0355-4950-ba3b-bed19ec8b00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (200000, 200)\n",
      "Target shape: (200000,)\n",
      "\n",
      "Train shape: (140000, 200) (140000,)\n",
      "Test shape: (60000, 200) (60000,)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 5: FEATURE ENGINEERING (BASIC)\n",
    "# ============================================\n",
    "\n",
    "# 1. Separate target and features\n",
    "TARGET_COL = \"target\"\n",
    "ID_COL = \"ID_code\"\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL, ID_COL])  # drop target + ID\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "\n",
    "# 2. Train-test split (70% train, 30% test) with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTrain shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ebe75fa-73e6-4d5a-9b58-38f42df88389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preprocessing + feature selection pipeline created.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 6: PREPROCESSING + FEATURE SELECTION\n",
    "# ============================================\n",
    "# We will create a common preprocessing + feature selection step\n",
    "# - SimpleImputer: handles missing values (if any)\n",
    "# - StandardScaler: scales features\n",
    "# - SelectKBest: keep top K important features (here K=50, you can change)\n",
    "\n",
    "K_FEATURES = 50  # you can tune this number later\n",
    "\n",
    "preprocess_and_select = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"select\", SelectKBest(score_func=mutual_info_classif, k=K_FEATURES))\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Preprocessing + feature selection pipeline created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5448571-8baa-4acf-93f0-0c2cd49eb4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to compare:\n",
      "- Logistic Regression\n",
      "- Random Forest\n",
      "- Gradient Boosting\n",
      "- KNN\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 7: DEFINE MULTIPLE MODELS FOR COMPARISON\n",
    "# ============================================\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, n_jobs=None),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "print(\"Models to compare:\")\n",
    "for name in models:\n",
    "    print(\"-\", name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ebc8a8-fc1a-4bb8-b2be-78fede7f72dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Training and evaluating: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 8: MODEL COMPARISON USING CROSS-VALIDATION\n",
    "# ============================================\n",
    "\n",
    "results = []\n",
    "\n",
    "# Stratified K-Fold to respect class imbalance\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"roc_auc\": \"roc_auc\",\n",
    "    \"f1\": \"f1\"\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Create a full pipeline: preprocess + model\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocess_select\", preprocess_and_select),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\n‚è≥ Training and evaluating: {name}\")\n",
    "    \n",
    "    cv_scores = cross_validate(\n",
    "        pipe,\n",
    "        X_train, y_train,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy_mean\": cv_scores[\"test_accuracy\"].mean(),\n",
    "        \"Accuracy_std\": cv_scores[\"test_accuracy\"].std(),\n",
    "        \"ROC_AUC_mean\": cv_scores[\"test_roc_auc\"].mean(),\n",
    "        \"ROC_AUC_std\": cv_scores[\"test_roc_auc\"].std(),\n",
    "        \"F1_mean\": cv_scores[\"test_f1\"].mean(),\n",
    "        \"F1_std\": cv_scores[\"test_f1\"].std()\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df_sorted = results_df.sort_values(by=\"ROC_AUC_mean\", ascending=False)\n",
    "\n",
    "print(\"\\nüìä Model Comparison (sorted by ROC_AUC_mean):\")\n",
    "display(results_df_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c02af-59d7-4fe3-8f13-0460ec4d07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 9: SELECT BEST MODEL (BASED ON ROC_AUC) AND TRAIN ON FULL TRAIN DATA\n",
    "# ============================================\n",
    "\n",
    "# Pick the model with highest ROC_AUC_mean\n",
    "best_model_name = results_df_sorted.iloc[0][\"Model\"]\n",
    "print(\"Best model selected:\", best_model_name)\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Build final pipeline with best model\n",
    "best_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess_select\", preprocess_and_select),\n",
    "    (\"model\", best_model)\n",
    "])\n",
    "\n",
    "# Fit on training data\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Best model trained on training data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5163ef12-f44a-4fbd-bc58-10298da22975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== TEST SET PERFORMANCE ====\n",
      "Accuracy : 0.9026\n",
      "Precision: 0.8046\n",
      "Recall   : 0.0403\n",
      "F1-score : 0.0768\n",
      "ROC-AUC  : 0.8081\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     53971\n",
      "           1       0.80      0.04      0.08      6029\n",
      "\n",
      "    accuracy                           0.90     60000\n",
      "   macro avg       0.85      0.52      0.51     60000\n",
      "weighted avg       0.89      0.90      0.86     60000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[53912    59]\n",
      " [ 5786   243]]\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 10: EVALUATION ON TEST SET\n",
    "# ============================================\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "y_proba = best_pipeline.predict_proba(X_test)[:, 1]  # probability for class 1\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(\"==== TEST SET PERFORMANCE ====\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "print(f\"ROC-AUC  : {roc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9166748e-a3cb-4627-a9e5-c36fb32fd299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Best model saved as: best_model_gradient_boosting.joblib\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 11: SAVE BEST MODEL FOR PRODUCTION\n",
    "# ============================================\n",
    "\n",
    "model_filename = f\"best_model_{best_model_name.replace(' ', '_').lower()}.joblib\"\n",
    "joblib.dump(best_pipeline, model_filename)\n",
    "\n",
    "print(f\"‚úÖ Best model saved as: {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e2cd7ca-8f5e-414e-b472-aa7638cea95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample customers (first 5 from test set):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163990</th>\n",
       "      <td>8.8310</td>\n",
       "      <td>-2.3016</td>\n",
       "      <td>13.2316</td>\n",
       "      <td>5.0266</td>\n",
       "      <td>9.8600</td>\n",
       "      <td>10.2081</td>\n",
       "      <td>3.6479</td>\n",
       "      <td>21.8577</td>\n",
       "      <td>-3.1201</td>\n",
       "      <td>5.7758</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.5464</td>\n",
       "      <td>10.3932</td>\n",
       "      <td>-0.5231</td>\n",
       "      <td>-7.0648</td>\n",
       "      <td>18.2618</td>\n",
       "      <td>-1.7615</td>\n",
       "      <td>12.5539</td>\n",
       "      <td>7.6870</td>\n",
       "      <td>15.0994</td>\n",
       "      <td>-16.9054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106916</th>\n",
       "      <td>17.8659</td>\n",
       "      <td>3.1619</td>\n",
       "      <td>13.0525</td>\n",
       "      <td>9.5777</td>\n",
       "      <td>11.4522</td>\n",
       "      <td>-16.2292</td>\n",
       "      <td>5.8872</td>\n",
       "      <td>10.4428</td>\n",
       "      <td>-0.7323</td>\n",
       "      <td>8.7069</td>\n",
       "      <td>...</td>\n",
       "      <td>7.7251</td>\n",
       "      <td>6.4649</td>\n",
       "      <td>1.7492</td>\n",
       "      <td>-3.1808</td>\n",
       "      <td>19.2917</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>10.6752</td>\n",
       "      <td>7.4027</td>\n",
       "      <td>12.0198</td>\n",
       "      <td>12.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189758</th>\n",
       "      <td>12.2995</td>\n",
       "      <td>-0.4513</td>\n",
       "      <td>8.6624</td>\n",
       "      <td>7.7633</td>\n",
       "      <td>10.2640</td>\n",
       "      <td>2.8404</td>\n",
       "      <td>6.2003</td>\n",
       "      <td>14.4520</td>\n",
       "      <td>0.8639</td>\n",
       "      <td>8.1660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4213</td>\n",
       "      <td>4.3329</td>\n",
       "      <td>1.4159</td>\n",
       "      <td>6.5954</td>\n",
       "      <td>15.7945</td>\n",
       "      <td>1.9027</td>\n",
       "      <td>2.8749</td>\n",
       "      <td>8.6100</td>\n",
       "      <td>22.3738</td>\n",
       "      <td>10.8293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185006</th>\n",
       "      <td>9.4057</td>\n",
       "      <td>-3.1699</td>\n",
       "      <td>8.0503</td>\n",
       "      <td>5.1969</td>\n",
       "      <td>11.5919</td>\n",
       "      <td>1.9257</td>\n",
       "      <td>5.2700</td>\n",
       "      <td>16.8097</td>\n",
       "      <td>1.7853</td>\n",
       "      <td>8.0217</td>\n",
       "      <td>...</td>\n",
       "      <td>13.3047</td>\n",
       "      <td>13.5090</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>6.2210</td>\n",
       "      <td>21.4579</td>\n",
       "      <td>0.4512</td>\n",
       "      <td>4.7943</td>\n",
       "      <td>9.1904</td>\n",
       "      <td>13.6194</td>\n",
       "      <td>-24.0796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175007</th>\n",
       "      <td>13.5909</td>\n",
       "      <td>7.8904</td>\n",
       "      <td>15.9594</td>\n",
       "      <td>7.4401</td>\n",
       "      <td>11.4552</td>\n",
       "      <td>-17.8994</td>\n",
       "      <td>5.0994</td>\n",
       "      <td>17.5617</td>\n",
       "      <td>2.2557</td>\n",
       "      <td>8.0235</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4529</td>\n",
       "      <td>9.6375</td>\n",
       "      <td>-0.6109</td>\n",
       "      <td>3.1691</td>\n",
       "      <td>19.6098</td>\n",
       "      <td>1.9964</td>\n",
       "      <td>7.4090</td>\n",
       "      <td>9.0665</td>\n",
       "      <td>15.5921</td>\n",
       "      <td>-5.3999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0   var_1    var_2   var_3    var_4    var_5   var_6    var_7  \\\n",
       "163990   8.8310 -2.3016  13.2316  5.0266   9.8600  10.2081  3.6479  21.8577   \n",
       "106916  17.8659  3.1619  13.0525  9.5777  11.4522 -16.2292  5.8872  10.4428   \n",
       "189758  12.2995 -0.4513   8.6624  7.7633  10.2640   2.8404  6.2003  14.4520   \n",
       "185006   9.4057 -3.1699   8.0503  5.1969  11.5919   1.9257  5.2700  16.8097   \n",
       "175007  13.5909  7.8904  15.9594  7.4401  11.4552 -17.8994  5.0994  17.5617   \n",
       "\n",
       "         var_8   var_9  ...  var_190  var_191  var_192  var_193  var_194  \\\n",
       "163990 -3.1201  5.7758  ...  -5.5464  10.3932  -0.5231  -7.0648  18.2618   \n",
       "106916 -0.7323  8.7069  ...   7.7251   6.4649   1.7492  -3.1808  19.2917   \n",
       "189758  0.8639  8.1660  ...   0.4213   4.3329   1.4159   6.5954  15.7945   \n",
       "185006  1.7853  8.0217  ...  13.3047  13.5090   0.6232   6.2210  21.4579   \n",
       "175007  2.2557  8.0235  ...   2.4529   9.6375  -0.6109   3.1691  19.6098   \n",
       "\n",
       "        var_195  var_196  var_197  var_198  var_199  \n",
       "163990  -1.7615  12.5539   7.6870  15.0994 -16.9054  \n",
       "106916  -0.6208  10.6752   7.4027  12.0198  12.9762  \n",
       "189758   1.9027   2.8749   8.6100  22.3738  10.8293  \n",
       "185006   0.4512   4.7943   9.1904  13.6194 -24.0796  \n",
       "175007   1.9964   7.4090   9.0665  15.5921  -5.3999  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True target values:      [0, 0, 0, 0, 1]\n",
      "Predicted probabilities: [0.076  0.0778 0.0352 0.0759 0.078 ]\n",
      "Predicted classes:       [0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 12: SAMPLE PREDICTION ON NEW DATA (OPTIONAL DEMO)\n",
    "# ============================================\n",
    "# Take a few rows from X_test as \"new customers\" and show predicted probabilities.\n",
    "\n",
    "sample_customers = X_test.iloc[:5]\n",
    "sample_true = y_test.iloc[:5]\n",
    "\n",
    "sample_proba = best_pipeline.predict_proba(sample_customers)[:, 1]\n",
    "sample_pred = best_pipeline.predict(sample_customers)\n",
    "\n",
    "print(\"Sample customers (first 5 from test set):\")\n",
    "display(sample_customers)\n",
    "\n",
    "print(\"\\nTrue target values:     \", list(sample_true.values))\n",
    "print(\"Predicted probabilities:\", np.round(sample_proba, 4))\n",
    "print(\"Predicted classes:      \", list(sample_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "289da9bf-970f-40cb-8c42-34253ddaf309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Challenges Faced:\n",
      "-----------------\n",
      "1. Anonymized features:\n",
      "   - No domain meaning for individual features.\n",
      "   - Could not perform domain-specific EDA/feature engineering.\n",
      "   - Solution: Treated all features as generic numeric variables and focused\n",
      "     on robust models (tree-based, ensemble methods).\n",
      "\n",
      "2. High-dimensional data (200 features):\n",
      "   - Risk of overfitting and longer training time.\n",
      "   - Solution: Used SelectKBest with mutual information to reduce to K\n",
      "     most informative features.\n",
      "\n",
      "3. Class imbalance (if target 1 is much smaller than target 0):\n",
      "   - Model could get high accuracy by predicting mostly class 0.\n",
      "   - Solution: Used stratified train-test split and ROC-AUC / F1 as key\n",
      "     metrics instead of accuracy alone. (Optionally we could use\n",
      "     class_weight='balanced' or resampling methods.)\n",
      "\n",
      "4. No missing values or few missing values:\n",
      "   - Still added SimpleImputer in pipeline to make it robust if data\n",
      "     quality changes in production. \n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 13: PLACEHOLDER ‚Äì CHALLENGES FACED (WRITE AS TEXT/MARKDOWN)\n",
    "# ============================================\n",
    "\n",
    "challenges_text = \"\"\"\n",
    "Challenges Faced:\n",
    "-----------------\n",
    "1. Anonymized features:\n",
    "   - No domain meaning for individual features.\n",
    "   - Could not perform domain-specific EDA/feature engineering.\n",
    "   - Solution: Treated all features as generic numeric variables and focused\n",
    "     on robust models (tree-based, ensemble methods).\n",
    "\n",
    "2. High-dimensional data (200 features):\n",
    "   - Risk of overfitting and longer training time.\n",
    "   - Solution: Used SelectKBest with mutual information to reduce to K\n",
    "     most informative features.\n",
    "\n",
    "3. Class imbalance (if target 1 is much smaller than target 0):\n",
    "   - Model could get high accuracy by predicting mostly class 0.\n",
    "   - Solution: Used stratified train-test split and ROC-AUC / F1 as key\n",
    "     metrics instead of accuracy alone. (Optionally we could use\n",
    "     class_weight='balanced' or resampling methods.)\n",
    "\n",
    "4. No missing values or few missing values:\n",
    "   - Still added SimpleImputer in pipeline to make it robust if data\n",
    "     quality changes in production. \"\"\"\n",
    "\n",
    "\n",
    "print(challenges_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80bfd12-9ed0-4515-a1fe-984e4311382d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
